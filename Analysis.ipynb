{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from typing import Dict, List, Union, Any, Tuple\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batchsize(path: str) -> int:\n",
    "    \"\"\"Extract max batch size from filename\"\"\"\n",
    "    fname = path.split(\"/\")[-1]\n",
    "    return int(fname.split(\"_\")[4][:-4])\n",
    "\n",
    "def get_replicas(path: str) -> int:\n",
    "    \"\"\"Extract nb of replicas from filename\"\"\"\n",
    "    fname = path.split(\"/\")[-1]\n",
    "    return int(fname.split(\"_\")[2])\n",
    "\n",
    "def unpack_data(folder: str, batch_sizes: List[int], replicas_range: range) -> List[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Returns the experimental data organised as follows:\n",
    "\n",
    "        - The top level list contains a `N` sublists. For each of `N` sub-lists the batch size is the same\n",
    "        - Each of the sub-lists contains `K` elements: each of them corresponds to a different number of replicas\n",
    "        - Each element of the sub-lists is a dict with keys `t_elapsed` and `explanations`. The values are lists with\n",
    "        len corresponding to the number of experimental runs for each batch size and replicas number combination\n",
    "     \"\"\"\n",
    "\n",
    "    fname_lists = filter_filenames(folder, replicas_range, batch_sizes)\n",
    "\n",
    "    # Load data in memory\n",
    "    data = []\n",
    "    for lst in fname_lists:\n",
    "        matching_files = []\n",
    "        for exp in lst:\n",
    "            with open(exp, 'rb') as f:\n",
    "                matching_files.append(pickle.load(f))\n",
    "        data.append(matching_files)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def filter_filenames(folder: str, cpu_range: range, batch_sizes: List[int]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Return the filenames from `folder` for specified `batch_sizes`, `cpu_range`. The response:\n",
    "\n",
    "        - Contains ``len(batch_sizes)`` sub-lists\n",
    "        - Each sublist contains ``len(list(cpu_range))`` filenames\n",
    "\n",
    "    Each sublist is sorted by the number of replicas (ascending order).\n",
    "    \"\"\"\n",
    "\n",
    "    fname_lists = [[] for _ in range(len(batch_sizes))]\n",
    "    batch_size_mapping = {batch_size: i for i, batch_size in enumerate(batch_sizes)}\n",
    "    for file in glob.glob(f'{folder}/ray_*.pkl'):\n",
    "        batch_size = get_batchsize(file)\n",
    "        if batch_size not in batch_size_mapping:\n",
    "            continue\n",
    "        ncpu = get_replicas(file)\n",
    "        if ncpu in cpu_range:\n",
    "            fname_lists[batch_size_mapping[batch_size]].append(file)\n",
    "\n",
    "    for lst in fname_lists:\n",
    "        lst.sort(key=get_replicas)\n",
    "\n",
    "    # pprint.pprint(fname_lists)\n",
    "\n",
    "    return fname_lists\n",
    "\n",
    "def get_stats(run, field):\n",
    "    \"\"\"\n",
    "    Calculate average runtime of a given (batch,ncpu_ setting.\n",
    "    \"\"\"\n",
    "    data = run[field]\n",
    "    avg = sum(data) / len(data)\n",
    "    std = np.std(data)\n",
    "    return avg, std\n",
    "\n",
    "\n",
    "def extract_timeseries(experiments:  List[List[Dict[str, Any]]], field: str) -> \\\n",
    "        Tuple[List[List[Union[float, Any]]], List[List[np.ndarray]]]:\n",
    "    \"\"\"\n",
    "    Extract time series of average runtime timeseries. See `unpack_data` for `experiments` structure. The means and\n",
    "    standard deviations output are organised as follows:\n",
    "\n",
    "        - Each entry in the top level list corresponds to a fixed batch size\n",
    "        - Each entry in the sublists corresponds to a different number of replicas\n",
    "    \"\"\"\n",
    "\n",
    "    means, stds = [], []\n",
    "    for batch_size in experiments:\n",
    "        tmp_mean, tmp_std = [], []\n",
    "        for replicas in batch_size:\n",
    "            mu, sigma = get_stats(replicas, field)\n",
    "            tmp_mean.append(mu)\n",
    "            tmp_std.append(sigma)\n",
    "        means.append(tmp_mean)\n",
    "        stds.append(tmp_std)\n",
    "\n",
    "    return means, stds\n",
    "\n",
    "\n",
    "def prepare_data(data, field='t_elapsed', decimals=3):\n",
    "    \"\"\"\n",
    "    Extract data from saved files and formats it so that a grouped bars plot can be created.\n",
    "    \"\"\"\n",
    "    means, stds = extract_timeseries(data, field)\n",
    "    mean_arrays, std_arrays = [], []\n",
    "    for mean_arr, std_arr in zip(means, stds):\n",
    "            mean_arrays.append(np.around(mean_arr, decimals=decimals))\n",
    "            std_arrays.append(np.around(std_arr, decimals=decimals))\n",
    "    return mean_arrays, std_arrays\n",
    "\n",
    "def compare_timing(means, stds, labels, cpu_range, bar_width=0.1, y_min=0, y_max=34.0, y_step=0.5,\n",
    "                   legend_pos=(1.24, -0.09), yticks_fontsize=20):\n",
    "    fig, ax = plt.subplots(figsize=(40, 20))\n",
    "\n",
    "    bar_positions = np.array(np.arange(1, cpu_range.stop - cpu_range.start + 1))\n",
    "    xticks = [str(x) for x in range(cpu_range.start, cpu_range.stop)]\n",
    "    bps = []\n",
    "    with sns.axes_style(\"white\"):\n",
    "        sns.set_style(\"ticks\")\n",
    "        sns.set_context(\"talk\")\n",
    "        for m, s, label in zip(means, stds, labels):\n",
    "            if len(m.shape) == 2:\n",
    "                m = m.squeeze()\n",
    "                s = s.squeeze()\n",
    "            bar_plot = ax.bar(bar_positions,\n",
    "                              m,\n",
    "                              bar_width,\n",
    "                              yerr=s,\n",
    "                              label=label,\n",
    "                              capsize=10\n",
    "                              )\n",
    "            bps.append(bar_plot)\n",
    "            bar_positions = bar_positions + bar_width\n",
    "\n",
    "        ax.set_xlabel(r'ncpu', fontsize=30)\n",
    "        ax.set_xticks(bar_positions - 2 * bar_width)\n",
    "        ax.set_xticklabels(xticks, rotation=45, fontsize=25)\n",
    "\n",
    "        ax.set_ylabel('Time (s)', fontsize=30)\n",
    "        ax.set_ylim(top=y_max)\n",
    "        ax.set_ylim(bottom=y_min)\n",
    "        y_ticks = np.arange(y_min, y_max, y_step)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_yticklabels(y_ticks, fontsize=yticks_fontsize)\n",
    "\n",
    "        ax.grid(True)\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        by_label = OrderedDict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys(), ncol=2, fontsize=20)\n",
    "        sns.despine()\n",
    "\n",
    "    return ax, bps\n",
    "\n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 5, 10]\n",
    "replicas_range = range(1, 4)\n",
    "\n",
    "folder = 'results'\n",
    "labels = ['ray_batch_{}'.format(size) for size in batch_sizes]\n",
    "data = unpack_data(folder, batch_sizes, replicas_range)\n",
    "mean, std = prepare_data(data)\n",
    "ax, bps = compare_timing(mean, std, labels, replicas_range, y_max=40, y_step=8)\n",
    "for bp in bps:\n",
    "    autolabel(ax, bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ray_replicas_3_maxbatch_1.pkl', 'rb') as f:\n",
    "    times = pickle.load(f)['t_elapsed']\n",
    "print(np.mean(times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
